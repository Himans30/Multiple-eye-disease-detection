{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Corrected import statement\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rescaling layer\n",
    "rescale = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "# Load train dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='dataset',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    label_mode='categorical',  # Assuming you have multiple classes\n",
    ")\n",
    "\n",
    "# Preprocess train dataset (rescale)\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "\n",
    "# Load validation dataset\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='dataset',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    label_mode='categorical',  # Assuming you have multiple classes\n",
    ")\n",
    "\n",
    "# Preprocess validation dataset (rescale)\n",
    "validation_ds = validation_ds.map(lambda x, y: (rescale(x), y))\n",
    "\n",
    "# Load test dataset\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='dataset',  # Specify the directory for the test dataset\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    label_mode='categorical',  # Assuming you have multiple classes\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Preprocess test dataset (rescale)\n",
    "test_ds = test_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first image shape in the training dataset\n",
    "print(\"Shape of the first image in the training dataset:\", next(iter(train_ds))[0][0].shape)\n",
    "# Check the first image shape in the validation dataset\n",
    "print(\"Shape of the first image in the validation dataset:\", next(iter(validation_ds))[0][0].shape)\n",
    "# Check the first image shape in the test dataset\n",
    "print(\"Shape of the first image in the test dataset:\", next(iter(test_ds))[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to store minimum and maximum pixel values\n",
    "min_pixel_value = float('inf')\n",
    "max_pixel_value = float('-inf')\n",
    "\n",
    "# Iterate through the dataset\n",
    "for images, _ in train_ds:\n",
    "    # Compute the minimum and maximum pixel values in the current batch of images\n",
    "    batch_min = tf.reduce_min(images)\n",
    "    batch_max = tf.reduce_max(images)\n",
    "    \n",
    "    # Update overall minimum and maximum pixel values\n",
    "    min_pixel_value = tf.minimum(min_pixel_value, batch_min)\n",
    "    max_pixel_value = tf.maximum(max_pixel_value, batch_max)\n",
    "\n",
    "# Print the minimum and maximum pixel values\n",
    "print(\"Minimum pixel value:\", min_pixel_value.numpy())\n",
    "print(\"Maximum pixel value:\", max_pixel_value.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(path, target_size=(256, 256), num_images=5):\n",
    "\n",
    "    # Get a list of image filenames\n",
    "    image_filenames = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "    if not image_filenames:\n",
    "        raise ValueError(\"No images found in the specified path\")\n",
    "\n",
    "    # Select random images\n",
    "    selected_images = random.sample(image_filenames, min(num_images, len(image_filenames)))\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3), facecolor='white')\n",
    "\n",
    "    # Display each image\n",
    "    for i, image_filename in enumerate(selected_images):\n",
    "        # Load image and resize\n",
    "        image_path = os.path.join(path, image_filename)\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize(target_size)\n",
    "\n",
    "        # Display image\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(image_filename)  # Set image filename as title\n",
    "\n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path containing the images to visualize\n",
    "path_to_visualize = \"dataset/cataract\"\n",
    "\n",
    "# Visualize 5 random images\n",
    "visualize_images(path_to_visualize, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path containing the images to visualize\n",
    "path_to_visualize = \"dataset/diabetic_retinopathy\"\n",
    "\n",
    "# Visualize 5 random images\n",
    "visualize_images(path_to_visualize, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path containing the images to visualize\n",
    "path_to_visualize = \"dataset/glaucoma\"\n",
    "\n",
    "# Visualize 5 random images\n",
    "visualize_images(path_to_visualize, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path containing the images to visualize\n",
    "path_to_visualize = \"dataset/normal\"\n",
    "\n",
    "# Visualize 5 random images\n",
    "visualize_images(path_to_visualize, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define RNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Reshape((64, 1)),  # Reshape for RNN input\n",
    "    tf.keras.layers.SimpleRNN(32),  # Simple RNN layer\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define early stopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=validation_ds,\n",
    "                    epochs=5,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define epochs\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(epochs, history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.plot(epochs, history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cataract.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('cateye.h5')\n",
    "\n",
    "# Define class labels (adjust based on your dataset)\n",
    "class_labels = ['Cataract', 'Diabetic Retinopathy', 'Glaucoma', 'Normal']\n",
    "\n",
    "def predict_eye_disease(img_path, target_size=(256, 256)):\n",
    "    \"\"\"Loads an image, preprocesses it, and predicts the eye disease class.\"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=target_size)  \n",
    "    img_array = image.img_to_array(img)  \n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    img_array = img_array / 255.0  \n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)  \n",
    "    predicted_class = np.argmax(prediction)  \n",
    "    confidence = np.max(prediction)  \n",
    "\n",
    "    print(f\"Predicted Eye Disease: {class_labels[predicted_class]}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Predicted Eye Disease: Cataract\n",
      "Confidence: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = r\"dataset\\cataract\\cataract_099.png\"  # Update with your image path\n",
    "predict_eye_disease(image_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
